{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftXnmgdtOuZs"
      },
      "source": [
        "# Universidad de Buenos Aires\n",
        "# Deep Learning - Examen\n",
        "# Agosto 2023\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "El examen comienza al momento de recibir este correo y la ventana de entrega estará abierta hasta el domingo 27 de Agosto a las 20:00hs. Toda comunicación con otros alumnos respecto del examen y la resolución de los ejercicios, queda estrictamente prohibida. Los exámenes serán comparados desde el punto de vista de la redacción, de los resultados y del código para determinar que el trabajo fue 100% individual y único. El examen es a libro abierto, pudiendo utilizar los contenidos vistos en clase y otra bibliografía. Todas las soluciones deben ser originales y si se toman ideas de fuentes externas deben ser correctamente citas incluyendo el correspondiente link o página de libro.\n",
        "\n",
        "El formato de entrega debe ser un “link a un colab” (compartir a las siguientes direcciones: maxit1992@gmail.com y lelectronfou@gmail.com ) o un “link a un notebook en un github público”.\n",
        "\n",
        "**Consideraciones a tener en cuenta:**\n",
        "- Se entregará 1 solo colab para la totalidad del examen.\n",
        "- Renombrar el archivo de la siguiente manera: **APELLIDO-NOMBRE-DL-Examen AGOSTO 2023.ipynb**\n",
        "- Los códigos deben poder ejecutarse.\n",
        "- Los resultados, cómo el código y las explicaciones deben quedar guardados y visualizables en el correspondiente link.\n",
        "- Prestar atención a las consignas, responder las preguntas cuando corresponda.\n",
        "\n"
      ],
      "metadata": {
        "id": "aEx1gM2sG4OP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlfSxrehmuYW"
      },
      "source": [
        "## Ejercicio 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dada la siguiente función:\n",
        "\n",
        "$$\n",
        "f(x,y) = (1.5 - x + xy)^2 + (2.25-x+xy^2)^2 + (2.625 -x + xy^3)^2\n",
        "$$\n",
        "\n",
        "\n",
        "Encontrar el punto donde la función es mínima y el valor de dicho mínimo:\n",
        "\n",
        "a. Utilizando SGD y cálculo de gradiente con regla de la cadena.\n",
        "\n",
        "b. Utilizando SGD y pytorch."
      ],
      "metadata": {
        "id": "AwCiDRncfsaI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 2"
      ],
      "metadata": {
        "id": "4CMta3Dj_Mjq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_hXG5W6KMBx"
      },
      "source": [
        "Si tiene una imagen a procesar de 1024x720x3 y desea aplicar en cascada, 2 capas de convolución, seguido por una capa de activación y una de pooling,  con las siguientes características:\n",
        "\n",
        "*Conv1:*\n",
        "* tamaño kernel = 7x7\n",
        "* padding = 2\n",
        "* stride = 1\n",
        "* número de kernel = 16\n",
        "\n",
        "*Conv2:*\n",
        "* tamaño kernel = 5x5\n",
        "* padding = 0\n",
        "* stride = 1\n",
        "* número de kernel = 32\n",
        "\n",
        "*activación*\n",
        "* Tanh()\n",
        "\n",
        "*pooling*\n",
        "* tamaño pooling = 5x5\n",
        "* padding pooling = 0\n",
        "* stride pooling = 5\n",
        "\n",
        "a) ¿Cual es el tamaño final de la salida y cuantos canales tiene?\n",
        "\n",
        "b) Si tiene que conectar esa salida a una `fully_connected` para clasificar 3 clases ¿que tamaño debe tener?\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 3\n",
        "\n"
      ],
      "metadata": {
        "id": "fvsqmJwx_Rb8"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABeIRvAkKLy7"
      },
      "source": [
        "\n",
        "Para la siguiente red neuronal recurrente, se pide expresar las ecuaciones \"*unfolded*\" de la salida de la misma y de sus estados ocultos, si el vector de entrada son 3 muestras secuenciadas de la variable $x(t)$.\n",
        "\n",
        "![b](https://drive.google.com/uc?export=view&id=1Fz46GTK7Oy_w5OEgwLCLfHFMr7b6-AnL)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Ecuaciones de la RNN:\n",
        "\n",
        "$$ \\hat{y}(t) = w_{h1y} * h1(t) + w_{h2y} * h2(t) + by$$\n",
        "\n",
        "$$ h1(t) = w_{xh1} * x(t) + w_{h1h1} * h1(t-1) + w_{h2h1} * h2(t-1)+ bh1$$\n",
        "$$ h2(t) = w_{xh2} * x(t) + w_{h2h2} * h2(t-1) + w_{h1h2} * h1(t-1)+ bh2 $$"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio 4"
      ],
      "metadata": {
        "id": "WL2PjUnT_Uvk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73yqE_Sslwif"
      },
      "source": [
        "\n",
        "\n",
        "Descargar el dataset del siguiente link: https://drive.google.com/file/d/1X8_G5BpQMi-Nnbtms2RL8lcWSxzD8ixd/view?usp=sharing. El dataset son compras de productos que diferentes clientes realizaron durante un black sales. El dataset contiene información sobre las transacciones y el objetivo es poder utilizar el dataset para crear diferentes modelos que puedan predecir cuánto un cliente está dispuesto a gastar en un producto en el futuro. Particularmente, vamos a tratar este problema como una clasificación binaria donde queremos averiguar si el cliente va a gastar mucha plata (más de 9000) o poca plata (menos de 9000).\n",
        "\n",
        "- a)\tEntrenar un modelo de deep learning que no utilice embeddings y que no emplee el `user_id` ni el `product_id`.\n",
        "- b)\tEntrenar un modelo de deep learning que utilice embeddings tanto para los productos como los usuarios. Realizar el mapeo de identificador de producto y usuarios a indices antes de separar el dataset en training, validation y testing.\n",
        "- c)\tGrafique las curvas de la loss function en función de las epochs de cada modelo y comente lo necesario.\n",
        "- d) Compare el score de cada modelo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eLQzdNeRjzym"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}